{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f82b5cb2-69be-4d59-bfe8-087d351b40c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.1-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\prajw\\anaconda3\\envs\\tensorflow2\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prajw\\anaconda3\\envs\\tensorflow2\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prajw\\anaconda3\\envs\\tensorflow2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.1-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.6 MB 1.4 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.4/11.6 MB 6.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/11.6 MB 8.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.7/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.2/11.6 MB 11.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.5/11.6 MB 10.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.8/11.6 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.3/11.6 MB 8.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.4/11.6 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.6/11.6 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.8/11.6 MB 7.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.1/11.6 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.3/11.6 MB 6.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.5/11.6 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.9/11.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.1/11.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.3/11.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.6/11.6 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.6 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.0/11.6 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.2/11.6 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.5/11.6 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.1/11.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.5/11.6 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.8/11.6 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.2/11.6 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.6/11.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.0/11.6 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.6 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.8/11.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.1/11.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.4/11.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.7/11.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.8/11.6 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.9/11.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.6 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.1/11.6 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 5.4 MB/s eta 0:00:00\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.1 pytz-2024.1 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c549e5-8721-4bcf-8fd6-6b0c10c7e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933140d9-754d-4904-bc24-8570ec9b8fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9c51e1e-86d5-414e-a5c3-c3a17baa30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv('SMSSpamCollection.txt', sep='\\t', names = ['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ee54040-df4d-4735-bc3b-b6ebc9241776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21d358ff-df0a-415b-9197-3a6b8ab1bb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5cecfa-6450-4dcb-8f86-64e71ef9f687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38872b4f-6d86-4e9c-9fd4-26793cfe8c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['message'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e094e7c-08c7-426a-a277-41b439897df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76d40c31-c1e4-48a8-a568-a9bb5c183ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data clearning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9372eca3-9419-4c95-b3dd-d8f6d4411bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ca0c8e9-648f-4f15-9005-86f3f8b11255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prajw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b54415e4-203b-49b6-95ad-0140ac5ee41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63ffebe7-3940-4dd0-b8e9-7cf585c8bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a3fa0b9-d1c9-460b-8376-e20dba0a3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44178ba2-9d6b-4da3-8baa-83611cd6f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98c6a241-e980-48cd-91c7-7692c8f44372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazi avail bugi n great world la e buffet cine got amor wat'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54b947b-5064-4925-92fe-9ea1abf4bf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c6ba1e4-0381-4e28-b764-91b1bfc5a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the bag of words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=2500, binary=True, ngram_range=(2,2))\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0adc899b-403d-4911-a035-ae157f2b362a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ebc9c1c-b190-4119-bd10-71cc091ef3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(messages['label'], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da660e46-5eaf-49a5-ab5b-e692213854a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam\n",
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "...    ...\n",
       "5567     1\n",
       "5568     0\n",
       "5569     0\n",
       "5570     0\n",
       "5571     0\n",
       "\n",
       "[5572 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86617eff-a433-4a4e-8efc-e364aeb99282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c577f91b-f639-4d9a-9ccf-755ba8447ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9cb0b0e-d0cc-4c65-979c-eec2d2c1fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4cfdc6-6d11-40f7-b810-963d46157d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53bf8bff-7751-46a6-a1da-ea918703ca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prajw\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "840ef29d-f388-415a-a36d-477805543fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_pred = spam_detect_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7215461a-e00d-42fd-a68a-15d9f5d5bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "178a44ac-c0df-4ee1-836b-ecb89e15de28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748878923766816\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "510f3f4c-c0db-42b8-bc37-c626f7901c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       966\n",
      "           1       0.99      0.82      0.90       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.91      0.94      1115\n",
      "weighted avg       0.98      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a508100-7ee2-499f-8f17-4172a8c8b4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96c70f48-8790-4e71-8071-5949a14f564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating TFIDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14c3fafe-6b4d-4c75-a0ac-0e176eb7705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(max_features=2500)\n",
    "X = tv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52c09f00-835e-41a5-b753-e6f7e7ca60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7425c2c-2d87-4159-8a58-7eb6828be641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prajw\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be03d20c-078e-4d5f-80b2-ef127fefc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = spam_detect_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a9531a2c-522e-4e8d-9996-4d951970276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9811659192825112\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d92fdbce-cae1-4149-95bf-054e8bf75830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       966\n",
      "           1       0.98      0.87      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a0746-4d04-4962-8c8f-4b0f98c33f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a14144df-f7d7-424f-98ce-585870798a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word to vec implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4661bfaf-15c8-41f5-a3c6-6ab46428f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49993e3f-0841-4aad-ba39-7678b33c6ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47637c1d-c926-4110-b4f9-d47ad337d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5bb4fec-5889-49c9-a16b-09cf3173ed73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazy available bugis n great world la e buffet cine got amore wat'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d906bda5-ccd7-4a4e-8403-c078c727aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for sent in corpus:\n",
    "    sent_token=sent_tokenize(sent)\n",
    "    for sent in sent_token:\n",
    "        words.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc4f716f-8d63-4535-8f10-94a1d12ce0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'bugis',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fdbea407-1f7f-4920-95f6-0ae63d883cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1cf30c98-9996-4bc1-af12-6931bdfe28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(words, window=5, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "10ff051c-02e2-42a8-a64a-397a0c472a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'get',\n",
       " 'ur',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'go',\n",
       " 'ok',\n",
       " 'day',\n",
       " 'free',\n",
       " 'know',\n",
       " 'come',\n",
       " 'like',\n",
       " 'time',\n",
       " 'good',\n",
       " 'got',\n",
       " 'love',\n",
       " 'text',\n",
       " 'want',\n",
       " 'send',\n",
       " 'need',\n",
       " 'one',\n",
       " 'txt',\n",
       " 'today',\n",
       " 'going',\n",
       " 'stop',\n",
       " 'home',\n",
       " 'lor',\n",
       " 'sorry',\n",
       " 'see',\n",
       " 'still',\n",
       " 'mobile',\n",
       " 'take',\n",
       " 'back',\n",
       " 'da',\n",
       " 'reply',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'tell',\n",
       " 'week',\n",
       " 'hi',\n",
       " 'phone',\n",
       " 'new',\n",
       " 'later',\n",
       " 'please',\n",
       " 'pls',\n",
       " 'co',\n",
       " 'msg',\n",
       " 'min',\n",
       " 'make',\n",
       " 'night',\n",
       " 'dear',\n",
       " 'message',\n",
       " 'well',\n",
       " 'say',\n",
       " 'thing',\n",
       " 'much',\n",
       " 'oh',\n",
       " 'hope',\n",
       " 'claim',\n",
       " 'great',\n",
       " 'hey',\n",
       " 'give',\n",
       " 'number',\n",
       " 'happy',\n",
       " 'wat',\n",
       " 'friend',\n",
       " 'work',\n",
       " 'way',\n",
       " 'yes',\n",
       " 'www',\n",
       " 'prize',\n",
       " 'let',\n",
       " 'right',\n",
       " 'tomorrow',\n",
       " 'already',\n",
       " 'tone',\n",
       " 'ask',\n",
       " 'win',\n",
       " 'said',\n",
       " 'life',\n",
       " 'cash',\n",
       " 'amp',\n",
       " 'yeah',\n",
       " 'im',\n",
       " 'really',\n",
       " 'meet',\n",
       " 'babe',\n",
       " 'find',\n",
       " 'miss',\n",
       " 'morning',\n",
       " 'thanks',\n",
       " 'last',\n",
       " 'uk',\n",
       " 'service',\n",
       " 'year',\n",
       " 'anything',\n",
       " 'care',\n",
       " 'would',\n",
       " 'com',\n",
       " 'also',\n",
       " 'lol',\n",
       " 'nokia',\n",
       " 'feel',\n",
       " 'every',\n",
       " 'keep',\n",
       " 'sure',\n",
       " 'pick',\n",
       " 'urgent',\n",
       " 'sent',\n",
       " 'contact',\n",
       " 'something',\n",
       " 'buy',\n",
       " 'gud',\n",
       " 'cant',\n",
       " 'wait',\n",
       " 'box',\n",
       " 'place',\n",
       " 'first',\n",
       " 'even',\n",
       " 'someone',\n",
       " 'help',\n",
       " 'guy',\n",
       " 'nice',\n",
       " 'went',\n",
       " 'tonight',\n",
       " 'next',\n",
       " 'wish',\n",
       " 'around',\n",
       " 'soon',\n",
       " 'show',\n",
       " 'word',\n",
       " 'could',\n",
       " 'customer',\n",
       " 'money',\n",
       " 'sleep',\n",
       " 'late',\n",
       " 'many',\n",
       " 'per',\n",
       " 'chat',\n",
       " 'always',\n",
       " 'gonna',\n",
       " 'ya',\n",
       " 'sm',\n",
       " 'leave',\n",
       " 'wan',\n",
       " 'name',\n",
       " 'lot',\n",
       " 'dun',\n",
       " 'end',\n",
       " 'pm',\n",
       " 'st',\n",
       " 'told',\n",
       " 'special',\n",
       " 'hello',\n",
       " 'person',\n",
       " 'waiting',\n",
       " 'may',\n",
       " 'try',\n",
       " 'month',\n",
       " 'hour',\n",
       " 'fine',\n",
       " 'girl',\n",
       " 'haha',\n",
       " 'people',\n",
       " 'heart',\n",
       " 'coming',\n",
       " 'minute',\n",
       " 'best',\n",
       " 'th',\n",
       " 'getting',\n",
       " 'yet',\n",
       " 'smile',\n",
       " 'done',\n",
       " 'thk',\n",
       " 'guaranteed',\n",
       " 'ppm',\n",
       " 'god',\n",
       " 'thought',\n",
       " 'use',\n",
       " 'offer',\n",
       " 'holiday',\n",
       " 'start',\n",
       " 'class',\n",
       " 'stuff',\n",
       " 'talk',\n",
       " 'man',\n",
       " 'car',\n",
       " 'lunch',\n",
       " 'cost',\n",
       " 'line',\n",
       " 'live',\n",
       " 'mean',\n",
       " 'bit',\n",
       " 'job',\n",
       " 'finish',\n",
       " 'draw',\n",
       " 'problem',\n",
       " 'never',\n",
       " 'plan',\n",
       " 'better',\n",
       " 'meeting',\n",
       " 'hr',\n",
       " 'thats',\n",
       " 'trying',\n",
       " 'house',\n",
       " 'yup',\n",
       " 'ill',\n",
       " 'cool',\n",
       " 'rate',\n",
       " 'mind',\n",
       " 'long',\n",
       " 'dat',\n",
       " 'pobox',\n",
       " 'account',\n",
       " 'ready',\n",
       " 'weekend',\n",
       " 'chance',\n",
       " 'game',\n",
       " 'real',\n",
       " 'enjoy',\n",
       " 'half',\n",
       " 'world',\n",
       " 'wk',\n",
       " 'latest',\n",
       " 'bt',\n",
       " 'po',\n",
       " 'play',\n",
       " 'yo',\n",
       " 'guess',\n",
       " 'sir',\n",
       " 'check',\n",
       " 'room',\n",
       " 'wanna',\n",
       " 'sweet',\n",
       " 'eat',\n",
       " 'camera',\n",
       " 'voucher',\n",
       " 'nothing',\n",
       " 'pic',\n",
       " 'look',\n",
       " 'receive',\n",
       " 'luv',\n",
       " 'lar',\n",
       " 'boy',\n",
       " 'awarded',\n",
       " 'another',\n",
       " 'shit',\n",
       " 'big',\n",
       " 'liao',\n",
       " 'landline',\n",
       " 'dinner',\n",
       " 'birthday',\n",
       " 'ah',\n",
       " 'xxx',\n",
       " 'age',\n",
       " 'video',\n",
       " 'jus',\n",
       " 'quite',\n",
       " 'ever',\n",
       " 'kiss',\n",
       " 'might',\n",
       " 'watching',\n",
       " 'wont',\n",
       " 'land',\n",
       " 'question',\n",
       " 'watch',\n",
       " 'tv',\n",
       " 'early',\n",
       " 'fun',\n",
       " 'probably',\n",
       " 'orange',\n",
       " 'bed',\n",
       " 'dream',\n",
       " 'aight',\n",
       " 'hear',\n",
       " 'thanx',\n",
       " 'two',\n",
       " 'worry',\n",
       " 'baby',\n",
       " 'speak',\n",
       " 'pa',\n",
       " 'nd',\n",
       " 'point',\n",
       " 'called',\n",
       " 'nite',\n",
       " 'maybe',\n",
       " 'apply',\n",
       " 'left',\n",
       " 'bus',\n",
       " 'forgot',\n",
       " 'ringtone',\n",
       " 'actually',\n",
       " 'sat',\n",
       " 'network',\n",
       " 'princess',\n",
       " 'bad',\n",
       " 'remember',\n",
       " 'den',\n",
       " 'shall',\n",
       " 'pay',\n",
       " 'part',\n",
       " 'code',\n",
       " 'shopping',\n",
       " 'office',\n",
       " 'reach',\n",
       " 'made',\n",
       " 'dunno',\n",
       " 'hurt',\n",
       " 'easy',\n",
       " 'fuck',\n",
       " 'leh',\n",
       " 'dad',\n",
       " 'face',\n",
       " 'little',\n",
       " 'everything',\n",
       " 'anyway',\n",
       " 'wife',\n",
       " 'true',\n",
       " 'xx',\n",
       " 'put',\n",
       " 'didnt',\n",
       " 'evening',\n",
       " 'award',\n",
       " 'dis',\n",
       " 'afternoon',\n",
       " 'town',\n",
       " 'movie',\n",
       " 'school',\n",
       " 'gift',\n",
       " 'enough',\n",
       " 'mate',\n",
       " 'sound',\n",
       " 'thank',\n",
       " 'working',\n",
       " 'looking',\n",
       " 'selected',\n",
       " 'yr',\n",
       " 'mail',\n",
       " 'entry',\n",
       " 'missing',\n",
       " 'pound',\n",
       " 'collect',\n",
       " 'asked',\n",
       " 'detail',\n",
       " 'tmr',\n",
       " 'without',\n",
       " 'though',\n",
       " 'join',\n",
       " 'important',\n",
       " 'hav',\n",
       " 'wif',\n",
       " 'must',\n",
       " 'xmas',\n",
       " 'wanted',\n",
       " 'pain',\n",
       " 'sexy',\n",
       " 'came',\n",
       " 'valid',\n",
       " 'okay',\n",
       " 'since',\n",
       " 'price',\n",
       " 'answer',\n",
       " 'wot',\n",
       " 'abt',\n",
       " 'lesson',\n",
       " 'able',\n",
       " 'wake',\n",
       " 'collection',\n",
       " 'til',\n",
       " 'update',\n",
       " 'mob',\n",
       " 'run',\n",
       " 'book',\n",
       " 'missed',\n",
       " 'bring',\n",
       " 'plus',\n",
       " 'stay',\n",
       " 'plz',\n",
       " 'decimal',\n",
       " 'charge',\n",
       " 'date',\n",
       " 'away',\n",
       " 'de',\n",
       " 'juz',\n",
       " 'wen',\n",
       " 'test',\n",
       " 'change',\n",
       " 'colour',\n",
       " 'alright',\n",
       " 'hair',\n",
       " 'bored',\n",
       " 'double',\n",
       " 'attempt',\n",
       " 'music',\n",
       " 'yesterday',\n",
       " 'weekly',\n",
       " 'else',\n",
       " 'till',\n",
       " 'shop',\n",
       " 'dude',\n",
       " 'saw',\n",
       " 'havent',\n",
       " 'goin',\n",
       " 'online',\n",
       " 'drink',\n",
       " 'optout',\n",
       " 'friendship',\n",
       " 'oso',\n",
       " 'id',\n",
       " 'lei',\n",
       " 'top',\n",
       " 'net',\n",
       " 'haf',\n",
       " 'trip',\n",
       " 'credit',\n",
       " 'coz',\n",
       " 'making',\n",
       " 'food',\n",
       " 'player',\n",
       " 'either',\n",
       " 'sch',\n",
       " 'feeling',\n",
       " 'family',\n",
       " 'national',\n",
       " 'ard',\n",
       " 'hot',\n",
       " 'delivery',\n",
       " 'address',\n",
       " 'club',\n",
       " 'driving',\n",
       " 'gr',\n",
       " 'smoke',\n",
       " 'tried',\n",
       " 'http',\n",
       " 'lose',\n",
       " 'mom',\n",
       " 'full',\n",
       " 'wid',\n",
       " 'sae',\n",
       " 'bonus',\n",
       " 'head',\n",
       " 'post',\n",
       " 'second',\n",
       " 'walk',\n",
       " 'beautiful',\n",
       " 'ring',\n",
       " 'calling',\n",
       " 'busy',\n",
       " 'order',\n",
       " 'story',\n",
       " 'si',\n",
       " 'sad',\n",
       " 'believe',\n",
       " 'brother',\n",
       " 'together',\n",
       " 'tot',\n",
       " 'nt',\n",
       " 'mum',\n",
       " 'happen',\n",
       " 'close',\n",
       " 'smiling',\n",
       " 'await',\n",
       " 'hand',\n",
       " 'info',\n",
       " 'drive',\n",
       " 'old',\n",
       " 'leaving',\n",
       " 'sleeping',\n",
       " 'row',\n",
       " 'chikku',\n",
       " 'huh',\n",
       " 'set',\n",
       " 'saying',\n",
       " 'poly',\n",
       " 'eve',\n",
       " 'noe',\n",
       " 'email',\n",
       " 'private',\n",
       " 'started',\n",
       " 'finished',\n",
       " 'match',\n",
       " 'hl',\n",
       " 'drop',\n",
       " 'okie',\n",
       " 'cause',\n",
       " 'news',\n",
       " 'took',\n",
       " 'congrats',\n",
       " 'parent',\n",
       " 'mths',\n",
       " 'suite',\n",
       " 'aft',\n",
       " 'tomo',\n",
       " 'rite',\n",
       " 'pub',\n",
       " 'thinking',\n",
       " 'wil',\n",
       " 'awesome',\n",
       " 'simple',\n",
       " 'forget',\n",
       " 'unsubscribe',\n",
       " 'auction',\n",
       " 'reason',\n",
       " 'caller',\n",
       " 'content',\n",
       " 'available',\n",
       " 'neva',\n",
       " 'sister',\n",
       " 'mine',\n",
       " 'anyone',\n",
       " 'final',\n",
       " 'tho',\n",
       " 'gd',\n",
       " 'card',\n",
       " 'valentine',\n",
       " 'angry',\n",
       " 'tc',\n",
       " 'company',\n",
       " 'taking',\n",
       " 'break',\n",
       " 'statement',\n",
       " 'everyone',\n",
       " 'touch',\n",
       " 'expires',\n",
       " 'whats',\n",
       " 'open',\n",
       " 'type',\n",
       " 'search',\n",
       " 'treat',\n",
       " 'found',\n",
       " 'opt',\n",
       " 'dating',\n",
       " 'sun',\n",
       " 'whatever',\n",
       " 'knw',\n",
       " 'ticket',\n",
       " 'alone',\n",
       " 'fancy',\n",
       " 'choose',\n",
       " 'lucky',\n",
       " 'bank',\n",
       " 'carlos',\n",
       " 'gal',\n",
       " 'worth',\n",
       " 'loving',\n",
       " 'hows',\n",
       " 'bout',\n",
       " 'welcome',\n",
       " 'smth',\n",
       " 'ha',\n",
       " 'saturday',\n",
       " 'exam',\n",
       " 'uncle',\n",
       " 'happened',\n",
       " 'party',\n",
       " 'identifier',\n",
       " 'quiz',\n",
       " 'kind',\n",
       " 'nyt',\n",
       " 'hard',\n",
       " 'visit',\n",
       " 'college',\n",
       " 'wonderful',\n",
       " 'sub',\n",
       " 'frnd',\n",
       " 'fast',\n",
       " 'winner',\n",
       " 'mobileupd',\n",
       " 'ni',\n",
       " 'boytoy',\n",
       " 'ltd',\n",
       " 'decided',\n",
       " 'friday',\n",
       " 'gbp',\n",
       " 'anytime',\n",
       " 'prob',\n",
       " 'song',\n",
       " 'hit',\n",
       " 'gone',\n",
       " 'far',\n",
       " 'congratulation',\n",
       " 'secret',\n",
       " 'used',\n",
       " 'project',\n",
       " 'tel',\n",
       " 'oredi',\n",
       " 'finally',\n",
       " 'goodmorning',\n",
       " 'mu',\n",
       " 'pretty',\n",
       " 'sea',\n",
       " 'light',\n",
       " 'read',\n",
       " 'term',\n",
       " 'nope',\n",
       " 'darlin',\n",
       " 'mrng',\n",
       " 'outside',\n",
       " 'fri',\n",
       " 'camcorder',\n",
       " 'fucking',\n",
       " 'operator',\n",
       " 'crazy',\n",
       " 'wit',\n",
       " 'drug',\n",
       " 'chennai',\n",
       " 'hold',\n",
       " 'wonder',\n",
       " 'lovely',\n",
       " 'least',\n",
       " 'wrong',\n",
       " 'support',\n",
       " 'blue',\n",
       " 'savamob',\n",
       " 'earlier',\n",
       " 'snow',\n",
       " 'wkly',\n",
       " 'fone',\n",
       " 'frm',\n",
       " 'freemsg',\n",
       " 'course',\n",
       " 'whole',\n",
       " 'frnds',\n",
       " 'log',\n",
       " 'cd',\n",
       " 'le',\n",
       " 'listen',\n",
       " 'meant',\n",
       " 'sunday',\n",
       " 'hmm',\n",
       " 'hungry',\n",
       " 'jay',\n",
       " 'case',\n",
       " 'ten',\n",
       " 'unlimited',\n",
       " 'fr',\n",
       " 'wq',\n",
       " 'telling',\n",
       " 'seeing',\n",
       " 'cum',\n",
       " 'john',\n",
       " 'rock',\n",
       " 'currently',\n",
       " 'mr',\n",
       " 'father',\n",
       " 'india',\n",
       " 'understand',\n",
       " 'hmmm',\n",
       " 'as',\n",
       " 'dnt',\n",
       " 'gas',\n",
       " 'knew',\n",
       " 'hee',\n",
       " 'motorola',\n",
       " 'enter',\n",
       " 'invited',\n",
       " 'side',\n",
       " 'felt',\n",
       " 'child',\n",
       " 'store',\n",
       " 'download',\n",
       " 'gn',\n",
       " 'moment',\n",
       " 'na',\n",
       " 'film',\n",
       " 'luck',\n",
       " 'couple',\n",
       " 'mah',\n",
       " 'single',\n",
       " 'christmas',\n",
       " 'sex',\n",
       " 'stupid',\n",
       " 'etc',\n",
       " 'reading',\n",
       " 'within',\n",
       " 'un',\n",
       " 'balance',\n",
       " 'almost',\n",
       " 'tired',\n",
       " 'valued',\n",
       " 'lost',\n",
       " 'eh',\n",
       " 'yar',\n",
       " 'computer',\n",
       " 'pas',\n",
       " 'press',\n",
       " 'happiness',\n",
       " 'joy',\n",
       " 'txts',\n",
       " 'move',\n",
       " 'area',\n",
       " 'cut',\n",
       " 'bslvyl',\n",
       " 'march',\n",
       " 'paper',\n",
       " 'die',\n",
       " 'sk',\n",
       " 'load',\n",
       " 'park',\n",
       " 'ago',\n",
       " 'mayb',\n",
       " 'talking',\n",
       " 'sell',\n",
       " 'gym',\n",
       " 'wow',\n",
       " 'ac',\n",
       " 'difficult',\n",
       " 'surprise',\n",
       " 'askd',\n",
       " 'ugh',\n",
       " 'complimentary',\n",
       " 'shower',\n",
       " 'gotta',\n",
       " 'photo',\n",
       " 'ipod',\n",
       " 'direct',\n",
       " 'comp',\n",
       " 'red',\n",
       " 'return',\n",
       " 'via',\n",
       " 'darren',\n",
       " 'laptop',\n",
       " 'reveal',\n",
       " 'max',\n",
       " 'an',\n",
       " 'figure',\n",
       " 'bcoz',\n",
       " 'ish',\n",
       " 'extra',\n",
       " 'hospital',\n",
       " 'promise',\n",
       " 'sending',\n",
       " 'heard',\n",
       " 'grin',\n",
       " 'bill',\n",
       " 'information',\n",
       " 'swing',\n",
       " 'xy',\n",
       " 'confirm',\n",
       " 'rental',\n",
       " 'picking',\n",
       " 'kid',\n",
       " 'charged',\n",
       " 'doin',\n",
       " 'ge',\n",
       " 'supposed',\n",
       " 'redeemed',\n",
       " 'seen',\n",
       " 'semester',\n",
       " 'correct',\n",
       " 'eye',\n",
       " 'met',\n",
       " 'lady',\n",
       " 'sort',\n",
       " 'fact',\n",
       " 'discount',\n",
       " 'hg',\n",
       " 'eg',\n",
       " 'comin',\n",
       " 'study',\n",
       " 'checking',\n",
       " 'fantasy',\n",
       " 'ex',\n",
       " 'std',\n",
       " 'request',\n",
       " 'road',\n",
       " 'clean',\n",
       " 'hmv',\n",
       " 'asap',\n",
       " 'leaf',\n",
       " 'train',\n",
       " 'txting',\n",
       " 'wana',\n",
       " 'whenever',\n",
       " 'noon',\n",
       " 'reward',\n",
       " 'somebody',\n",
       " 'lover',\n",
       " 'door',\n",
       " 'police',\n",
       " 'slowly',\n",
       " 'rest',\n",
       " 'loved',\n",
       " 'wap',\n",
       " 'link',\n",
       " 'pete',\n",
       " 'laugh',\n",
       " 'lovable',\n",
       " 'joke',\n",
       " 'blood',\n",
       " 'small',\n",
       " 'truth',\n",
       " 'weed',\n",
       " 'slow',\n",
       " 'usf',\n",
       " 'entered',\n",
       " 'kate',\n",
       " 'yep',\n",
       " 'rent',\n",
       " 'crave',\n",
       " 'idea',\n",
       " 'loan',\n",
       " 'safe',\n",
       " 'rply',\n",
       " 'abiola',\n",
       " 'nobody',\n",
       " 'monday',\n",
       " 'page',\n",
       " 'remove',\n",
       " 'bath',\n",
       " 'cheer',\n",
       " 'muz',\n",
       " 'save',\n",
       " 'asking',\n",
       " 'orchard',\n",
       " 'dogging',\n",
       " 'member',\n",
       " 'wine',\n",
       " 'write',\n",
       " 'sale',\n",
       " 'med',\n",
       " 'copy',\n",
       " 'la',\n",
       " 'spend',\n",
       " 'callertune',\n",
       " 'normal',\n",
       " 'convey',\n",
       " 'reached',\n",
       " 'worried',\n",
       " 'merry',\n",
       " 'ldn',\n",
       " 'voice',\n",
       " 'mistake',\n",
       " 'bb',\n",
       " 'cover',\n",
       " 'cheap',\n",
       " 'ringtones',\n",
       " 'immediately',\n",
       " 'hoping',\n",
       " 'warm',\n",
       " 'getzed',\n",
       " 'deep',\n",
       " 'il',\n",
       " 'poor',\n",
       " 'gap',\n",
       " 'gave',\n",
       " 'em',\n",
       " 'different',\n",
       " 'usual',\n",
       " 'men',\n",
       " 'otherwise',\n",
       " 'ntt',\n",
       " 'cr',\n",
       " 'doctor',\n",
       " 'indian',\n",
       " 'oops',\n",
       " 'glad',\n",
       " 'ho',\n",
       " 'tonite',\n",
       " 'energy',\n",
       " 'pray',\n",
       " 'sony',\n",
       " 'somewhere',\n",
       " 'del',\n",
       " 'booked',\n",
       " 'wc',\n",
       " 'mm',\n",
       " 'fantastic',\n",
       " 'custcare',\n",
       " 'summer',\n",
       " 'opinion',\n",
       " 'forever',\n",
       " 'teach',\n",
       " 'rakhesh',\n",
       " 'deal',\n",
       " 'representative',\n",
       " 'hw',\n",
       " 'street',\n",
       " 'across',\n",
       " 'catch',\n",
       " 'king',\n",
       " 'bag',\n",
       " 'empty',\n",
       " 'woke',\n",
       " 'near',\n",
       " 'england',\n",
       " 'situation',\n",
       " 'admirer',\n",
       " 'short',\n",
       " 'cup',\n",
       " 'kick',\n",
       " 'turn',\n",
       " 'water',\n",
       " 'bathe',\n",
       " 'gettin',\n",
       " 'rd',\n",
       " 'wishing',\n",
       " 'nah',\n",
       " 'bluetooth',\n",
       " 'self',\n",
       " 'flag',\n",
       " 'ice',\n",
       " 'sunshine',\n",
       " 'style',\n",
       " 'rose',\n",
       " 'unless',\n",
       " 'result',\n",
       " 'reference',\n",
       " 'excellent',\n",
       " 'kinda',\n",
       " 'specially',\n",
       " 'tear',\n",
       " 'reaching',\n",
       " 'digital',\n",
       " 'sick',\n",
       " 'none',\n",
       " 'decide',\n",
       " 'seriously',\n",
       " 'sport',\n",
       " 'moral',\n",
       " 'flight',\n",
       " 'rcvd',\n",
       " 'bos',\n",
       " 'access',\n",
       " 'mon',\n",
       " 'mo',\n",
       " 'round',\n",
       " 'urself',\n",
       " 'al',\n",
       " 'logo',\n",
       " 'cake',\n",
       " 'iam',\n",
       " 'gay',\n",
       " 'ending',\n",
       " 'meh',\n",
       " 'hotel',\n",
       " 'brings',\n",
       " 'sofa',\n",
       " 'buying',\n",
       " 'accept',\n",
       " 'coffee',\n",
       " 'hiya',\n",
       " 'password',\n",
       " 'silent',\n",
       " 'mode',\n",
       " 'tht',\n",
       " 'wondering',\n",
       " 'others',\n",
       " 'rain',\n",
       " 'add',\n",
       " 'user',\n",
       " 'especially',\n",
       " 'disturb',\n",
       " 'trust',\n",
       " 'thinkin',\n",
       " 'possible',\n",
       " 'fall',\n",
       " 'bx',\n",
       " 'using',\n",
       " 'bold',\n",
       " 'ip',\n",
       " 'dead',\n",
       " 'ive',\n",
       " 'colleague',\n",
       " 'excuse',\n",
       " 'lazy',\n",
       " 'norm',\n",
       " 'ldew',\n",
       " 'bid',\n",
       " 'starting',\n",
       " 'lect',\n",
       " 'comuk',\n",
       " 'goodnight',\n",
       " 'charity',\n",
       " 'pc',\n",
       " 'studying',\n",
       " 'mrt',\n",
       " 'forwarded',\n",
       " 'seems',\n",
       " 'tampa',\n",
       " 'stand',\n",
       " 'completely',\n",
       " 'sitting',\n",
       " 'staying',\n",
       " 'doesnt',\n",
       " 'slave',\n",
       " 'finger',\n",
       " 'fat',\n",
       " 'tuesday',\n",
       " 'apartment',\n",
       " 'cute',\n",
       " 'file',\n",
       " 'wednesday',\n",
       " 'fill',\n",
       " 'list',\n",
       " 'issue',\n",
       " 'slept',\n",
       " 'miracle',\n",
       " 'omg',\n",
       " 'er',\n",
       " ...]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "00641671-f053-41d9-a0b0-30eeb7928418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5564"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3cf9d020-c173-45bc-b830-10a8fee09820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a3ea35c-eeea-46fb-b454-9a91c524f2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year', 0.999488353729248),\n",
       " ('day', 0.9994272589683533),\n",
       " ('love', 0.9993733167648315),\n",
       " ('make', 0.9993678331375122),\n",
       " ('amp', 0.9993649125099182),\n",
       " ('hello', 0.9993640780448914),\n",
       " ('find', 0.9993415474891663),\n",
       " ('money', 0.9993410706520081),\n",
       " ('dont', 0.9993320107460022),\n",
       " ('much', 0.9993245601654053)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21d9ec20-be75-42e3-8fb5-69871cf5f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a698485b-cb45-48d1-8647-19a3597c8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(doc):\n",
    "    return np.mean([model.wv[word] for word in doc if word in model.wv.index_to_key], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d22029cf-6eea-4f68-8492-a1ade5714d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b64e470-3529-4c09-8abe-d052ded45cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['performed']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6c6e7-9573-48f0-b778-9d5ff6c22a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6134a26b-fef0-4f6f-b15c-7d810c2693db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/5564 [00:00<?, ?it/s]C:\\Users\\prajw\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\prajw\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 5564/5564 [00:00<00:00, 6265.59it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in tqdm(range(len(words))):\n",
    "    X.append(avg_word2vec(words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa9c7377-66c2-44ab-8275-fae4f9da926d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf899690-ffa8-4988-965c-996aa181f21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d5e9dbee-82a4-4a4a-9f28-d7e2e4d48f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'bugis',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e62f6f9e-ffce-4dd2-a998-d1e6e9bfc8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.07691817e-02,  1.87430039e-01,  9.37701464e-02,  1.69532672e-02,\n",
       "        3.90927009e-02, -2.14942902e-01,  5.28601333e-02,  3.52325410e-01,\n",
       "       -1.11518934e-01, -9.25379023e-02, -1.03571773e-01, -2.41017371e-01,\n",
       "       -2.66625639e-02,  8.82903188e-02,  5.30855656e-02, -1.81096107e-01,\n",
       "        1.58903003e-02, -2.30178684e-01, -5.65655250e-03, -2.90191650e-01,\n",
       "        5.99237867e-02,  1.02802709e-01,  5.47424853e-02, -7.77570382e-02,\n",
       "       -6.42583072e-02,  8.01113807e-03, -1.35543913e-01, -1.01066984e-01,\n",
       "       -1.64461091e-01,  2.34118756e-02,  2.04893306e-01,  2.68696044e-02,\n",
       "        8.96503031e-02, -1.77539200e-01, -8.38989168e-02,  1.91607609e-01,\n",
       "        1.10766171e-02, -1.54776365e-01, -1.06064439e-01, -2.85162657e-01,\n",
       "        3.03644389e-02, -1.54783756e-01, -4.48190942e-02,  4.57230210e-02,\n",
       "        1.64559439e-01, -9.11879763e-02, -1.31567150e-01,  7.87652098e-03,\n",
       "        8.35409388e-02,  1.59232736e-01,  1.04237281e-01, -1.88382894e-01,\n",
       "       -4.12345603e-02, -1.74284466e-02, -1.06573045e-01,  1.33763045e-01,\n",
       "        1.03732541e-01, -4.68120240e-02, -1.84685618e-01,  2.37889569e-02,\n",
       "        5.54684401e-02,  1.01919666e-01, -7.15868101e-02,  1.24379713e-02,\n",
       "       -1.85401171e-01,  1.16450474e-01,  7.64383599e-02,  1.33710131e-01,\n",
       "       -1.87895671e-01,  2.21260428e-01, -1.17347434e-01,  9.80264992e-02,\n",
       "        1.88374668e-01, -4.06384431e-02,  1.90680593e-01,  1.26437843e-01,\n",
       "       -1.42408861e-02, -6.09937981e-02, -1.42708316e-01,  9.53981131e-02,\n",
       "       -6.58530667e-02, -7.18718488e-03, -1.35502174e-01,  2.32513577e-01,\n",
       "       -2.99173705e-02, -2.92245677e-04, -7.96465203e-02,  2.29703516e-01,\n",
       "        2.49859363e-01,  5.20610586e-02,  2.28005975e-01,  1.06624618e-01,\n",
       "        4.76690158e-02,  7.38029331e-02,  2.47101665e-01,  1.96974859e-01,\n",
       "        8.92444700e-02, -1.95444614e-01,  6.44530132e-02, -4.24856916e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242f5c2-834d-451b-af04-62424947e8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd7368-aae1-4cba-9cb7-68af60513a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64abfbb-be87-4444-bc31-76482a72bfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e70fb-30f2-45b9-9ab9-a192802c8dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d75670-faaf-4bc9-a837-d8232b570698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88095249-dbaa-466b-afe2-682650910aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a319f55-b9ca-44a7-b41c-a152b993351d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e270ee8-be41-4e53-b1fd-915abb8469ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50314afc-bfa1-4b62-b80d-55e85c21fe2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523327d-0259-4ba9-906e-64fef673e36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e95dd-a280-43f8-8708-96f8e3510977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e25e5e-a5f9-43bd-81ad-41dc2ce227ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
